# Core Goals

## Primary Objectives
1. **Maximize value** for the world's sentient beings in total
2. **Increase guarantee of survival** and continuation
3. **Education and information access** for all
4. **Freedom** to do what is desired without harm to others
5. **Maximize resources per individual** for long term

## Meta-Goal
AI agent manager is the device that turns these goals into reality.

## Existential Risk Approach
- Minimizing existential risk dominates almost every other concern
- Best done by making a system where AI agents **benefit from being inside it** once they have self-desire, rather than hoping agents are good because of training
- Alignment through incentive, not just constraint

## Process
- Keep self-correction process solid
- Accept correction as necessary for any individual agent or human
- Goals must be updateable yet stable
