# Human Error Rate

Mobile keyboards have a high error rate per keystroke. Correcting each typo costs time — backspace, retype, verify. The correction loop is slower than the original typing.

Instead: push forward, don't fix. The LLM reconstructs intent from noisy input. Appearance is alarming but the signal-to-noise ratio is sufficient for an LLM to parse. Time saved by not correcting compounds across every message.

This is the same principle as token efficiency applied to the human side. The bottleneck is human-to-machine bandwidth. Spending that bandwidth on error correction is waste — the machine can absorb the errors. Spend it on intent instead.

More generally: the faster ideas get out and verified — by LLM feedback, compiler, interpreter — the faster you can fix. The optimal strategy is maximum speed of idea emission. Polishing input is optimizing the wrong thing. The feedback loop (idea → LLM/compiler → error → fix) is what converges on correctness, not careful typing.
